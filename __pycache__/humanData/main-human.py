import requests
import time
import json
import csv
from urllib.parse import urlencode
import io

BASE_URL = "https://dportal.kdca.go.kr"
MAIN_URL = f"{BASE_URL}/pot/is/rginEDW.do"

# ì‹¤ì œ í™•ì¸ëœ ì •í™•í•œ URLë“¤

SIGNGU_URL = f"{BASE_URL}/pot/is/selectAreaSignguCdListEDWAjax.do" # ì‹œêµ°êµ¬ì½”ë“œë¥¼ ê°€ì ¸ì˜´
STATS_URL = f"{BASE_URL}/pot/is/bassAreaStatsContentEDW.do" # í˜ì´ì§• êµ¬ì„±?
DATA_URL = f"{BASE_URL}/pot/is/selectBassAreaStatsListEDWAjax.do" # ì‹¤ì œë°ì´í„° ê°€ì ¸ì˜´

def get_realistic_headers(referer=None):
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
            "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        ),
        "Accept": "*/*",
        "Accept-Language": "ko-KR,ko;q=0.9,en;q=0.8",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
        "X-Requested-With": "XMLHttpRequest",
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "Origin": BASE_URL,
    }
    if referer:
        headers["Referer"] = referer
    return headers

def json_to_csv(data_list, filename):
    """JSON ë°ì´í„°ë¥¼ UTF-8 CSVë¡œ ë³€í™˜ (í•œê¸€ ê¹¨ì§ ì™„ì „ í•´ê²°)"""
    """JSON ë°ì´í„°ë¥¼ UTF-8 CSVë¡œ ë³€í™˜ (ì»¬ëŸ¼ ìˆ«ì ìˆœì„œ ì •ë ¬)"""
    if not data_list:
        print(f"âš ï¸ ë°ì´í„° ì—†ìŒ: {filename}")
        return False
    
 # ëª¨ë“  ì»¬ëŸ¼ëª… ìˆ˜ì§‘
    all_columns = set()
    for row in data_list:
        all_columns.update(row.keys())
    
    # COLUMN ìˆ«ì ìˆœì„œëŒ€ë¡œ ì •ë ¬ (ìì—° ì •ë ¬)
    def natural_sort_key(col):
        """COLUMN1, COLUMN2, ..., COLUMN10 ìˆœì„œë¡œ ì •ë ¬"""
        if col.startswith('COLUMN'):
            try:
                return int(col.replace('COLUMN', ''))
            except:
                return 999999  # ìˆ«ì ì•„ë‹Œ ê²½ìš° ë§¨ ë’¤
        return 999999
    
    columns = sorted(list(all_columns), key=natural_sort_key)
    
    # UTF-8 BOM ì¶”ê°€ (Excelì—ì„œ í•œê¸€ ì •ìƒ í‘œì‹œ)
    bom = '\ufeff'
    
    with io.open(filename, 'w', encoding='utf-8-sig', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=columns, extrasaction='ignore')
        writer.writeheader()
        writer.writerows(data_list)
    
    print(f"âœ… UTF-8 BOM CSV ì €ì¥: {filename} ({len(data_list)}í–‰)")
    return True    
def get_all_signgu_list(session):
    """ê²½ê¸° ëª¨ë“  ì‹œêµ°êµ¬ ë¦¬ìŠ¤íŠ¸ ìë™ ê°€ì ¸ì˜¤ê¸°"""
    print("ğŸ” ê²½ê¸° ì‹œêµ°êµ¬ ë¦¬ìŠ¤íŠ¸ ìë™ ì¡°íšŒ...")
    signgu_payload = {"areaCtprvnCd": "08"}
    signgu_resp = session.post(
        SIGNGU_URL,
        data=signgu_payload,
        headers=get_realistic_headers(MAIN_URL),
        timeout=10
    )
    
    print(f"   ì‹œêµ°êµ¬ ì‘ë‹µì½”ë“œ: {signgu_resp.status_code}")
    print("signgu_resp::::::", signgu_resp.content[:500], "...")  # ì²˜ìŒ 500ìë§Œ
    
    if signgu_resp.status_code == 200:
        try:
            signgu_json = signgu_resp.json()
            signgu_list = signgu_json.get('value', [])
            print(f"âœ… ê²½ê¸° ì‹œêµ°êµ¬ {len(signgu_list)}ê°œ ì¡°íšŒ ì™„ë£Œ!")
            
            # ì½”ë“œ:ì´ë¦„ ë”•ì…”ë„ˆë¦¬ ìƒì„±
            regions = {}
            for item in signgu_list:
                code = item['areaSignguCd']
                name = item['signguNm'].replace(' ', '_')  # íŒŒì¼ëª…ìš© ê³µë°± ì œê±°
                regions[code] = name
            return regions
        except:
            print("âŒ ì‹œêµ°êµ¬ JSON íŒŒì‹± ì‹¤íŒ¨")
            return {}
    return {}

def download_for_region(session, signgu_cd, signgu_name, year="2025"):
    """íŠ¹ì • ì‹œêµ°êµ¬ ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
    print(f"\nğŸ“¥ {signgu_name} ({signgu_cd}) ë‹¤ìš´ë¡œë“œ...")
    
    # 3. í†µê³„ ë‚´ìš© ìš”ì²­
    stats_payload = {
        "frmNm": "areaDissMonthWeekFrm",
        "areaCtprvnCdArr": "",
        "areaSignguCdArr": "",
        "icdgrpCdArr": "01,02,03",
        "icdCdArr": "A0013,NB0005,NB0006,NB0007,NB0017,NC0005,NC0006,NC0007,NC0010,NC0014,NC0018,NC0021,NC0025,NC0026",  # ì‹¤ì œ ì‚¬ìš©ëœ ì½”ë“œ
        "startDt": year,
        "dateType": "week",
        "icdgrpCd": ["01", "02", "03"], #ê°ì—¼ë³‘ ë“±ê¸‰1~3ë“±ê¸‰ê¸‰
        "icdCd": ["NB0005","NB0006","NB0007","NB0017","NC0005","NC0006","NC0007", "NC0010", "NC0014", "NC0018","NC0021","NC0025","NC0026"], # ì§ˆë³‘ì½”ë“œë“œ
        "areaCtprvnCd": "08", #ê²½ê¸°ë„ ì‹œêµ°êµ¬ì½”ë“œ ì„œìš¸ì€ "01"
        "areaSignguCd": signgu_cd,
        "patntType": "1",  # ì‹¤ì œ ì‚¬ìš©ê°’
        "areaType": "1"
    }
    session.post(STATS_URL, data=stats_payload, headers=get_realistic_headers(MAIN_URL), timeout=10)
    time.sleep(0.7)
    
    # 4. ì‹¤ì œ ë°ì´í„° ìš”ì²­ (selectBassAreaStatsListEDWAjax.do)
    print("4. ì‹¤ì œ ë°ì´í„° ìš”ì²­...")
    data_payload = {
        "frmNm": "areaDissMonthWeekFrm",
        "areaCtprvnCdArr": "",
        "areaSignguCdArr": "",
        "icdgrpCdArr": "01,02,03",
        "icdCdArr": "A0013,NB0005,NB0006,NB0007,NB0017,NC0005,NC0006,NC0007,NC0010,NC0014,NC0018,NC0021,NC0025,NC0026",  # ì‹¤ì œ ì‚¬ìš©ëœ ì½”ë“œ
        "startDt": year,
        "dateType": "week",
        "icdgrpCd": ["01", "02", "03"], #ê°ì—¼ë³‘ ë“±ê¸‰1~3ë“±ê¸‰ê¸‰
        "icdCd": ["NB0005","NB0006","NB0007","NB0017","NC0005","NC0006","NC0007", "NC0010", "NC0014", "NC0018","NC0021","NC0025","NC0026"], # ì§ˆë³‘ì½”ë“œë“œ
        "areaCtprvnCd": "08", #ê²½ê¸°ë„ ì‹œêµ°êµ¬ì½”ë“œ ì„œìš¸ì€ "01"
        "areaSignguCd": signgu_cd,
        "patntType": "1",  # ì‹¤ì œ ì‚¬ìš©ê°’
        "areaType": "1"
    }

    data_resp = session.post(
        DATA_URL,
        data=data_payload,
        headers=get_realistic_headers(MAIN_URL),
        timeout=10
    )
    print(f"   ë°ì´í„° ì‘ë‹µ: {data_resp.status_code}")
    
    if data_resp.status_code == 200:
        try:
            data_json = data_resp.json()
            data_list = data_json.get('value', {}).get('data', [])
            
            filename = f"kdca_{year}_week_ê²½ê¸°_{signgu_name}_{signgu_cd}.csv"
            if json_to_csv(data_list, filename):
                print(f"âœ… ì €ì¥: {filename} ({len(data_list)}í–‰)")
                return True
        except Exception as e:
            print(f"âŒ íŒŒì‹±ì˜¤ë¥˜: {e}")
    print(f"âŒ ì‹¤íŒ¨: {signgu_cd}")
    return False

if __name__ == "__main__":
    session = requests.Session()
    
    # 1. ë©”ì¸ í˜ì´ì§€ ë°©ë¬¸
    print("ğŸŒ ë©”ì¸ í˜ì´ì§€ ì ‘ì†...")
    session.get(MAIN_URL, headers=get_realistic_headers(), timeout=10)
    time.sleep(1)
    
    # 2. ëª¨ë“  ì‹œêµ°êµ¬ ë¦¬ìŠ¤íŠ¸ ìë™ ì¡°íšŒ
    gyenggi_regions = get_all_signgu_list(session)
    
    if not gyenggi_regions:
        print("âŒ ì‹œêµ°êµ¬ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨!")
        exit()
    
    # TEST_CASESëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ (ìˆ˜ë™ í…ŒìŠ¤íŠ¸ìš©)
    TEST_CASES = [
        ("075", "2025"),  # ê°€í‰êµ° 2025
        ("076", "2025")   # ê³ ì–‘ì‹œ ë•ì–‘êµ¬ 2025
    ]
    
    success_count = 0
    
    # 3. TEST_CASES ë¨¼ì € ì‹¤í–‰
    """ print("\nğŸ¯ TEST_CASES ì‹¤í–‰...")
    for signgu_cd, year in TEST_CASES:
        if signgu_cd in gyenggi_regions:
            if download_for_region(session, signgu_cd, gyenggi_regions[signgu_cd], year):
                success_count += 1
        time.sleep(60) #ipë³´í˜¸
    
    print(f"\nâœ… TEST ì™„ë£Œ: {success_count}/{len(TEST_CASES)} ì„±ê³µ") """
    
    # 4. ì „ì²´ ìë™ ì‹¤í–‰ ì›í•˜ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
    print("\nğŸš€ ì „ì²´ ê²½ê¸° 40ê°œ ìë™ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
    for signgu_cd, signgu_name in gyenggi_regions.items():
        download_for_region(session, signgu_cd, signgu_name, "2025")
        time.sleep(60) #ipë³´í˜¸