import requests
from bs4 import BeautifulSoup
import time
import pandas as pd
import re
from urllib.parse import urljoin, parse_qs, urlparse

# ì„¸ì…˜ ìƒì„± (ì¿ í‚¤ ë° ìƒíƒœ ìœ ì§€)
session = requests.Session()

# ë” ì‚¬ì‹¤ì ì¸ í—¤ë” ì„¤ì • (ë´‡ ì°¨ë‹¨ ë°©ì§€)
def get_headers():
    return {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
        'Accept-Encoding': 'gzip, deflate, br',
        'Cache-Control': 'max-age=0',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Sec-Fetch-User': '?1',
        'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"'
    }

def get_ajax_headers():
    return {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'application/json, text/javascript, */*; q=0.01',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
        'Accept-Encoding': 'gzip, deflate, br',
        'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
        'X-Requested-With': 'XMLHttpRequest',
        'Referer': 'https://www.foodsafetykorea.go.kr/portal/healthyfoodlife/searchHomeHF.do',
        'Origin': 'https://www.foodsafetykorea.go.kr',
        'Connection': 'keep-alive',
        'Sec-Fetch-Dest': 'empty',
        'Sec-Fetch-Mode': 'cors',
        'Sec-Fetch-Site': 'same-origin',
        'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"'
    }

BASE_URL = "https://www.foodsafetykorea.go.kr"
AJAX_SEARCH_URL = f"{BASE_URL}/portal/healthyfoodlife/searchHomeHFProc.do"
DETAIL_URL = f"{BASE_URL}/portal/healthyfoodlife/searchHomeHFDetail.do"

def search_omega3_products(page_no=1, search_term="ì…€ë¡œë‹‰ìŠ¤", show_cnt=10):
    """ì˜¤ë©”ê°€3 ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ê²€ìƒ‰"""
    # í˜ì´ì§€ ì¸ë±ìŠ¤ ê³„ì‚° (1ë¶€í„° ì‹œì‘)
    start_idx = (page_no - 1) * show_cnt + 1
    
    list_params = {
        "menu_no": "2823",
        "menu_grp": "MENU_NEW01", 
        "menuNm": "ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ê²€ìƒ‰",
        "copyUrl": "https://www.foodsafetykorea.go.kr:443/portal/healthyfoodlife/searchHomeHF.do?menu_grp=MENU_NEW01&menu_no=2823",
        "mberId": "",
        "mberNo": "",
        "favorListCnt": "0",
        "search_code": "05",  # 05: ì œí’ˆëª… ë˜ëŠ” ì—…ì†Œëª…
        "search_word": search_term,
        "show_cnt": str(show_cnt),  # í˜ì´ì§€ë‹¹ í‘œì‹œ ê°œìˆ˜
        "start_idx": str(start_idx)  # ì‹œì‘ ì¸ë±ìŠ¤ (1ë¶€í„° ì‹œì‘!)
    }
    
    try:
        print(f"[í˜ì´ì§€ {page_no}] ë¸Œë¼ìš°ì € ë™ì‘ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘...")
        
        # 1ë‹¨ê³„: ë©”ì¸ í˜ì´ì§€ ë°©ë¬¸ (ì¿ í‚¤ ë° ì„¸ì…˜ ì„¤ì •)
        if page_no == 1:  # ì²« í˜ì´ì§€ì—ì„œë§Œ ì´ˆê¸°í™”
            session.get(BASE_URL, headers=get_headers(), timeout=30)
            time.sleep(0.5)
            search_page_url = f"{BASE_URL}/portal/healthyfoodlife/searchHomeHF.do"
            session.get(search_page_url, headers=get_headers(), timeout=30)
            time.sleep(1)
        
        # AJAX ê²€ìƒ‰ ìš”ì²­
        response = session.post(AJAX_SEARCH_URL, data=list_params, headers=get_ajax_headers(), timeout=30)
        response.encoding = "utf-8"
        
        print(f"[í˜ì´ì§€ {page_no}] ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
        
        if response.status_code != 200:
            print(f"[í˜ì´ì§€ {page_no}] HTTP ì˜¤ë¥˜: {response.status_code}")
            return None
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            json_data = response.json()
            print(f"[í˜ì´ì§€ {page_no}] JSON íŒŒì‹± ì„±ê³µ: {len(json_data)}ê°œ ì œí’ˆ")
            return json_data
        except ValueError as json_error:
            print(f"[í˜ì´ì§€ {page_no}] JSON íŒŒì‹± ì‹¤íŒ¨: {json_error}")
            return None
            
    except requests.exceptions.Timeout:
        print(f"[í˜ì´ì§€ {page_no}] ìš”ì²­ ì‹œê°„ ì´ˆê³¼ (30ì´ˆ)")
        return None
    except Exception as e:
        print(f"[í˜ì´ì§€ {page_no}] ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return None

def get_product_detail_rancidity(prdlst_report_no, search_term="ì…€ë¡œë‹‰ìŠ¤",show_cnt=10,start_idx=1):
    """ê°œë³„ ì œí’ˆì˜ ìƒì„¸ ì •ë³´ì—ì„œ ì‚°íŒ¨ë„ ì •ë³´ ì¡°íšŒ"""
    detail_params = {
        "menu_no": "2672",
        "menu_grp": "MENU_NEW01", 
        "menuNm": "ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ê²€ìƒ‰",
        "copyUrl": "https://www.foodsafetykorea.go.kr:443/portal/healthyfoodlife/searchHomeHFDetail.do?prdlstReportLedgNo="+prdlst_report_no
        +"&search_word=" + search_term
        +"&search_code=01&start_idx=1&show_cnt=10&menu_no=2823&menu_grp=MENU_NEW01",
        "mberId": "",
        "mberNo": "",
        "favorListCnt": "0",
        "search_code": "05",  # 05: ì œí’ˆëª… ë˜ëŠ” ì—…ì†Œëª…
        "search_word": search_term,
        "show_cnt": str(show_cnt),  # í˜ì´ì§€ë‹¹ í‘œì‹œ ê°œìˆ˜
        "start_idx": str(start_idx),  # ì‹œì‘ ì¸ë±ìŠ¤ (1ë¶€í„° ì‹œì‘!)
        "prdlst_report_no": prdlst_report_no
    }
    

    try:
        print(f"    ìƒì„¸ í˜ì´ì§€ ìš”ì²­: {prdlst_report_no}")
        
        # ìƒì„¸ í˜ì´ì§€ ìš”ì²­
        response = session.get(DETAIL_URL, params=detail_params, headers=get_headers(), timeout=30)
        response.encoding = "utf-8"
        
        print(f"    ì‘ë‹µ ìƒíƒœ: {response.status_code}")
        print(f"    ì‘ë‹µ ê¸¸ì´: {len(response.text)} ë¬¸ì")
        
        # ì‘ë‹µ ë‚´ìš© í™•ì¸ (ë””ë²„ê¹…ìš©)
        if "ê¸°ì¤€ ë° ê·œê²©" not in response.text:
            print(f"    âŒ 'ê¸°ì¤€ ë° ê·œê²©' í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            # ì‘ë‹µ ë‚´ìš©ì˜ ì¼ë¶€ë¥¼ ì¶œë ¥í•´ì„œ í™•ì¸
            print(f"    ì‘ë‹µ ìƒ˜í”Œ: {response.text[:500]}...")
            return None
        
        soup = BeautifulSoup(response.text, "html.parser")
        
        # ë°©ë²• 1: ì •í™•í•œ HTML êµ¬ì¡°ë¡œ ì°¾ê¸°
        standard_cell = None
        
        # <th>ê¸°ì¤€ ë° ê·œê²©</th> ì°¾ê¸°
        for th in soup.find_all("th"):
            th_text = th.get_text(strip=True)
            if "ê¸°ì¤€" in th_text and "ê·œê²©" in th_text:
                print(f"    âœ… 'ê¸°ì¤€ ë° ê·œê²©' th íƒœê·¸ ë°œê²¬: {th_text}")
                # ê°™ì€ í–‰ì˜ td ì°¾ê¸°
                tr = th.find_parent("tr")
                if tr:
                    standard_cell = tr.find("td")
                    if standard_cell:
                        print(f"    âœ… ê¸°ì¤€ ë° ê·œê²© td íƒœê·¸ ë°œê²¬")
                        break
        
        if not standard_cell:
            print(f"    âŒ ê¸°ì¤€ ë° ê·œê²© ì…€ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            # ë°©ë²• 2: ë” ë„“ì€ ë²”ìœ„ë¡œ ê²€ìƒ‰
            print(f"    ëŒ€ì•ˆ ê²€ìƒ‰ ì‹œë„...")
            all_tds = soup.find_all("td")
            for td in all_tds:
                td_text = td.get_text()
                if "ì‚°ê°€" in td_text and "ê³¼ì‚°í™”ë¬¼ê°€" in td_text:
                    print(f"    âœ… ì‚°íŒ¨ë„ ì •ë³´ê°€ í¬í•¨ëœ td ë°œê²¬!")
                    standard_cell = td
                    break
        
        if not standard_cell:
            print(f"    âŒ ì‚°íŒ¨ë„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return None
            
        # ê¸°ì¤€ ë° ê·œê²© í…ìŠ¤íŠ¸ ì¶”ì¶œ
        standard_text = standard_cell.get_text()
        print(f"    ğŸ“„ ê¸°ì¤€ ë° ê·œê²© í…ìŠ¤íŠ¸ ê¸¸ì´: {len(standard_text)} ë¬¸ì")
        print(f"    ğŸ“„ í…ìŠ¤íŠ¸ ìƒ˜í”Œ: {standard_text[:200]}...")
        
        # ì‚°íŒ¨ë„ ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
        rancidity_info = extract_rancidity_info(standard_text)
        
        if rancidity_info:
            print(f"    âœ… ì‚°íŒ¨ë„ ì •ë³´ ì¶”ì¶œ ì„±ê³µ: {rancidity_info}")
        else:
            print(f"    âŒ ì‚°íŒ¨ë„ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨")
        
        return rancidity_info
            
    except Exception as e:
        print(f"    âŒ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ ({prdlst_report_no}): {e}")
        import traceback
        traceback.print_exc()
        return None

            
    except Exception as e:
        print(f"    ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ ({prdlst_report_no}): {e}")
        return None

def extract_rancidity_info(standard_text):
    """ê¸°ì¤€ ë° ê·œê²© í…ìŠ¤íŠ¸ì—ì„œ ì‚°íŒ¨ë„ ì •ë³´ ì¶”ì¶œ"""
    rancidity_info = {
        "ì‚°ê°€": None,
        "ê³¼ì‚°í™”ë¬¼ê°€": None, 
        "ì•„ë‹ˆì‹œë”˜ê°€": None,
        "ì´ì‚°í™”ê°€": None
    }
    
    print(f"    ğŸ” ì‚°íŒ¨ë„ ì •ë³´ ì¶”ì¶œ ì‹œì‘...")
    
    # ì‚°ê°€ ì¶”ì¶œ (ë” ì •í™•í•œ íŒ¨í„´)
    acid_patterns = [
        r"ì‚°ê°€\s*[:ï¼š]\s*([0-9.]+)\s*ì´í•˜",
        r"ì‚°ê°€\s*([0-9.]+)\s*ì´í•˜",
        r"ã†ì‚°ê°€\s*[:ï¼š]\s*([0-9.]+)\s*ì´í•˜"
    ]
    for pattern in acid_patterns:
        acid_match = re.search(pattern, standard_text, re.IGNORECASE)
        if acid_match:
            rancidity_info["ì‚°ê°€"] = float(acid_match.group(1))
            print(f"    âœ… ì‚°ê°€ ë°œê²¬: {rancidity_info['ì‚°ê°€']}")
            break
    
    # ê³¼ì‚°í™”ë¬¼ê°€ ì¶”ì¶œ
    peroxide_patterns = [
        r"ê³¼ì‚°í™”ë¬¼ê°€\s*[:ï¼š]\s*([0-9.]+)\s*ì´í•˜",
        r"ê³¼ì‚°í™”ë¬¼ê°€\s*([0-9.]+)\s*ì´í•˜",
        r"ã†ê³¼ì‚°í™”ë¬¼ê°€\s*[:ï¼š]\s*([0-9.]+)\s*ì´í•˜"
    ]
    for pattern in peroxide_patterns:
        peroxide_match = re.search(pattern, standard_text, re.IGNORECASE)
        if peroxide_match:
            rancidity_info["ê³¼ì‚°í™”ë¬¼ê°€"] = float(peroxide_match.group(1))
            print(f"    âœ… ê³¼ì‚°í™”ë¬¼ê°€ ë°œê²¬: {rancidity_info['ê³¼ì‚°í™”ë¬¼ê°€']}")
            break
    
    # ì•„ë‹ˆì‹œë”˜ê°€ ì¶”ì¶œ
    anisidine_patterns = [
        r"ì•„ë‹ˆì‹œë”˜ê°€\s*[:ï¼š]\s*([0-9.]+)\s*ì´í•˜",
        r"ì•„ë‹ˆì‹œë”˜ê°€\s*([0-9.]+)\s*ì´í•˜",
        r"ã†ì•„ë‹ˆì‹œë”˜ê°€\s*[:ï¼š]\s*([0-9.]+)\s*ì´í•˜",
        r"ì• ë‹ˆì‹œë”˜ê°€\s*[:ï¼š]\s*([0-9.]+)\s*ì´í•˜"
    ]
    for pattern in anisidine_patterns:
        anisidine_match = re.search(pattern, standard_text, re.IGNORECASE)
        if anisidine_match:
            rancidity_info["ì•„ë‹ˆì‹œë”˜ê°€"] = float(anisidine_match.group(1))
            print(f"    âœ… ì•„ë‹ˆì‹œë”˜ê°€ ë°œê²¬: {rancidity_info['ì•„ë‹ˆì‹œë”˜ê°€']}")
            break
    
    # ì´ì‚°í™”ê°€ ì¶”ì¶œ
    totox_patterns = [
        r"ì´ì‚°í™”ê°€\s*[:ï¼š]\s*([0-9.]+)\s*ì´í•˜",
        r"ì´ì‚°í™”ê°€\s*([0-9.]+)\s*ì´í•˜",
        r"ã†ì´ì‚°í™”ê°€\s*[:ï¼š]\s*([0-9.]+)\s*ì´í•˜",
        r"ì´\s*ì˜¥ì‹œê°€\s*[:ï¼š]\s*([0-9.]+)\s*ì´í•˜",
        r"totox\s*[:ï¼š]\s*([0-9.]+)\s*ì´í•˜"
    ]
    for pattern in totox_patterns:
        totox_match = re.search(pattern, standard_text, re.IGNORECASE)
        if totox_match:
            rancidity_info["ì´ì‚°í™”ê°€"] = float(totox_match.group(1))
            print(f"    âœ… ì´ì‚°í™”ê°€ ë°œê²¬: {rancidity_info['ì´ì‚°í™”ê°€']}")
            break
    
    # ì‚°íŒ¨ë„ ì •ë³´ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ë°˜í™˜
    found_values = [k for k, v in rancidity_info.items() if v is not None]
    if found_values:
        print(f"    ğŸ“Š ì¶”ì¶œëœ ì‚°íŒ¨ë„ ì •ë³´: {found_values}")
        return rancidity_info
    else:
        print(f"    âŒ ì‚°íŒ¨ë„ ì •ë³´ ì—†ìŒ")
        return None


def check_rancidity_standards(rancidity_info):
    """ì‚°íŒ¨ë„ ê¸°ì¤€ í†µê³¼ ì—¬ë¶€ í™•ì¸"""
    standards = {
        "ì‚°ê°€": 3.0,
        "ê³¼ì‚°í™”ë¬¼ê°€": 5.0,
        "ì•„ë‹ˆì‹œë”˜ê°€": 20.0,
        "ì´ì‚°í™”ê°€": 26.0
    }
    
    results = {}
    for key, standard in standards.items():
        if rancidity_info.get(key) is not None:
            value = rancidity_info[key]
            results[f"{key}_í†µê³¼"] = value <= standard
            results[f"{key}_ê°’"] = value
            results[f"{key}_ê¸°ì¤€"] = standard
        else:
            results[f"{key}_í†µê³¼"] = None
            results[f"{key}_ê°’"] = None
            results[f"{key}_ê¸°ì¤€"] = standard
    
    return results

def extract_product_info(response_data, include_rancidity=False, search_term="ì…€ë¡œë‹‰ìŠ¤", show_cnt=10, start_idx=1):
    """ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì œí’ˆ ì •ë³´ ì¶”ì¶œ (ì‚°íŒ¨ë„ ì •ë³´ í¬í•¨)"""
    products = []
    
    if not isinstance(response_data, list):
        print("ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ í˜•ì‹")
        return products
    
    print(f"JSON ë¦¬ìŠ¤íŠ¸ ì‘ë‹µ ì²˜ë¦¬ ì¤‘... ({len(response_data)}ê°œ)")
    
    for i, item in enumerate(response_data, 1):
        try:
            # ê¸°ë³¸ ì œí’ˆ ì •ë³´
            product_info = {
                "ë²ˆí˜¸": item.get("no", ""),
                "ì œí’ˆëª…": item.get("prdlst_nm", ""),
                "ì—…ì†Œëª…": item.get("bssh_nm", ""),
                "ì‹ ê³ ë²ˆí˜¸": item.get("prdlst_report_no", ""),
                "ë“±ë¡ì¼": item.get("prms_dt", ""),
                "prdlstReportNo": item.get("prdlst_report_no", ""),
                "ì´_ê°œìˆ˜": item.get("total_count", "")
            }
            
            # ì‚°íŒ¨ë„ ì •ë³´ ì¶”ì¶œ
            if include_rancidity and product_info["prdlstReportNo"]:
                print(f"  ({i}/{len(response_data)}) {product_info['ì œí’ˆëª…']} ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
                
                # search_term ì œê±°í•˜ê³  í˜¸ì¶œ
                rancidity_info = get_product_detail_rancidity(product_info["prdlstReportNo"], search_term, show_cnt, start_idx)
                
                if rancidity_info:
                    # ì‚°íŒ¨ë„ ì •ë³´ ì¶”ê°€
                    product_info.update(rancidity_info)
                    
                    # ê¸°ì¤€ í†µê³¼ ì—¬ë¶€ í™•ì¸
                    standards_check = check_rancidity_standards(rancidity_info)
                    product_info.update(standards_check)
                    
                    print(f"    â†’ âœ… ì‚°íŒ¨ë„ ì •ë³´ ë°œê²¬!")
                else:
                    print(f"    â†’ âŒ ì‚°íŒ¨ë„ ì •ë³´ ì—†ìŒ")
                
                # ì„œë²„ ë¶€í•˜ ë°©ì§€ (ë§¤ìš° ì¤‘ìš”!)
                time.sleep(2)
            
            products.append(product_info)
            
        except Exception as e:
            print(f"ì œí’ˆ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            continue

    print(f"ì¶”ì¶œëœ ì œí’ˆ ìˆ˜: {len(products)}")
    return products

def collect_all_omega3_products(search_term="ì…€ë¡œë‹‰ìŠ¤", show_cnt=10):
    """ëª¨ë“  ì˜¤ë©”ê°€3 ì œí’ˆ ìˆ˜ì§‘ (ì‚°íŒ¨ë„ ì •ë³´ í¬í•¨)"""
    print(f"'{search_term}' ê²€ìƒ‰ì–´ë¡œ ëª¨ë“  ì œí’ˆ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("=" * 80)
    
    # ì²« ë²ˆì§¸ í˜ì´ì§€ë¡œ ì „ì²´ ê°œìˆ˜ í™•ì¸
    first_page_data = search_omega3_products(1, search_term, show_cnt)
    if not first_page_data or len(first_page_data) == 0:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    total_count = int(first_page_data[0].get("total_count", 0))
    print(f"ì´ {total_count}ê°œ ì œí’ˆ ë°œê²¬!")
    
    # í•„ìš”í•œ í˜ì´ì§€ ìˆ˜ ê³„ì‚°
    total_pages = (total_count + show_cnt - 1) // show_cnt
    print(f"{show_cnt}ê°œì”© {total_pages}í˜ì´ì§€ì— ê±¸ì³ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
    print("=" * 80)
    
    all_products = []
    
    for page in range(1, total_pages + 1):
        print(f"\nğŸ” [{page}/{total_pages}] í˜ì´ì§€ ì²˜ë¦¬ ì¤‘...")
        
        if page == 1:
            # ì²« í˜ì´ì§€ëŠ” ì´ë¯¸ ê°€ì ¸ì™”ìŒ
            response_data = first_page_data
        else:
            response_data = search_omega3_products(page, search_term, show_cnt)
            if not response_data:
                print(f"âŒ {page} í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨")
                break
        
        # ì œí’ˆ ì •ë³´ ì¶”ì¶œ (ì‚°íŒ¨ë„ ì •ë³´ í¬í•¨)
        products = extract_product_info(response_data, include_rancidity=True, search_term=search_term)
        if not products:
            print(f"âŒ {page} í˜ì´ì§€ì—ì„œ ì œí’ˆ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨")
            break
        
        all_products.extend(products)
        print(f"âœ… {page} í˜ì´ì§€ì—ì„œ {len(products)}ê°œ ì œí’ˆ ì²˜ë¦¬ ì™„ë£Œ (ëˆ„ì : {len(all_products)}ê°œ)")
        
        # í˜ì´ì§€ ê°„ ì„œë²„ ë¶€í•˜ ë°©ì§€ (ì¤‘ìš”!)
        if page < total_pages:
            print("â±ï¸ ë‹¤ìŒ í˜ì´ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•´ 3ì´ˆ ëŒ€ê¸°...")
            time.sleep(3)
    
    print("\n" + "=" * 80)
    print(f"ğŸ‰ ì´ {len(all_products)}ê°œ ì œí’ˆ ìˆ˜ì§‘ ì™„ë£Œ!")
    return all_products

def save_results(results, filename="omega3_rancidity_complete.csv"):
    """ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
    if results:
        df = pd.DataFrame(results)
        df.to_csv(filename, index=False, encoding="utf-8-sig")
        print(f"\nğŸ“„ ê²°ê³¼ê°€ {filename} íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì‚°íŒ¨ë„ ì •ë³´ê°€ ìˆëŠ” ì œí’ˆ ê°œìˆ˜ ì¶œë ¥
        rancidity_columns = ['ì‚°ê°€', 'ê³¼ì‚°í™”ë¬¼ê°€', 'ì•„ë‹ˆì‹œë”˜ê°€', 'ì´ì‚°í™”ê°€']
        rancidity_products = df[df[rancidity_columns].notna().any(axis=1)]
        print(f"ğŸ“Š ì´ {len(df)}ê°œ ì œí’ˆ ì¤‘ {len(rancidity_products)}ê°œ ì œí’ˆì—ì„œ ì‚°íŒ¨ë„ ì •ë³´ ë°œê²¬")
        
        if len(rancidity_products) > 0:
            # ì‚°íŒ¨ë„ ì •ë³´ê°€ ìˆëŠ” ì œí’ˆë“¤ë§Œ ë³„ë„ ì €ì¥
            rancidity_filename = "omega3_with_rancidity_complete.csv"
            rancidity_products.to_csv(rancidity_filename, index=False, encoding="utf-8-sig")
            print(f"ğŸ“„ ì‚°íŒ¨ë„ ì •ë³´ê°€ ìˆëŠ” ì œí’ˆì´ {rancidity_filename}ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ì‚°íŒ¨ë„ ê¸°ì¤€ì„ ëª¨ë‘ í†µê³¼í•œ ì œí’ˆ í•„í„°ë§
            rancidity_pass_cols = ['ì‚°ê°€_í†µê³¼', 'ê³¼ì‚°í™”ë¬¼ê°€_í†µê³¼', 'ì•„ë‹ˆì‹œë”˜ê°€_í†µê³¼', 'ì´ì‚°í™”ê°€_í†µê³¼']
            passed_products = rancidity_products[rancidity_products[rancidity_pass_cols].all(axis=1, skipna=True)]
            
            if not passed_products.empty:
                print(f"âœ… ì‚°íŒ¨ë„ ê¸°ì¤€ì„ ëª¨ë‘ í†µê³¼í•œ ì œí’ˆ: {len(passed_products)}ê°œ")
                passed_filename = "omega3_passed_standards_complete.csv"
                passed_products.to_csv(passed_filename, index=False, encoding="utf-8-sig")
                print(f"ğŸ“„ ê¸°ì¤€ í†µê³¼ ì œí’ˆì´ {passed_filename}ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                print("âš ï¸ ì‚°íŒ¨ë„ ê¸°ì¤€ì„ ëª¨ë‘ í†µê³¼í•œ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
        
        return df
    else:
        print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ§¬ ì˜¤ë©”ê°€3 ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì™„ì „ ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    print("=" * 80)
    
    # ì „ì²´ ì˜¤ë©”ê°€3 ì œí’ˆ ìˆ˜ì§‘ (ì‚°íŒ¨ë„ ì •ë³´ í¬í•¨)
    print("ğŸ” 1ë‹¨ê³„: ëª¨ë“  ì˜¤ë©”ê°€3 ì œí’ˆ ìˆ˜ì§‘ ë° ì‚°íŒ¨ë„ ì •ë³´ ì¶”ì¶œ")
    all_products = collect_all_omega3_products(search_term="ì…€ë¡œë‹‰ìŠ¤", show_cnt=10, )
    
    if not all_products:
        print("âŒ ìˆ˜ì§‘ëœ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ¯ ì´ {len(all_products)}ê°œì˜ ì˜¤ë©”ê°€3 ì œí’ˆ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    
    # ê²°ê³¼ ì €ì¥
    print("\nğŸ’¾ 2ë‹¨ê³„: ê²°ê³¼ ì €ì¥")
    df = save_results(all_products)
    
    print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("=" * 80)

if __name__ == "__main__":
    main()